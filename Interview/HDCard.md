#### 경력기술서
```
2014.01~2014.02 LG CNS 인턴
 LG CNS AA플랫폼팀(現 AI빅데이터기술팀) 에서 SQL on Hadoop을 팀 플랫폼에 적용하기 위한 POC 업무를 진행하였습니다.
SQL on Hadoop 기술들의 성능을 정리 및 Review 하였고 그 중 Apache Tajo를 선정하여 팀내 클러스터에 설치 후 테스트 진행 및 결과를 보고하였습니다.

2015.11~2016.02 L통신사 상품 컨텐츠 추천 개발(Phase 1)
 통신사에서 보유한 로그데이터와 사용자의 개인 정보등을 활용하여 상품을 추천하는 업무를 수행하였습니다.
팀에 보유하고 있는 플랫폼을 구축한 뒤 고객의 요청사항에 맞는 솔루션 설치를 진행하였으며 RDBMS에 저장되어있는 데이터를 수집 및 HDFS에 적재 후 Hive 및 MapReduce를 이용하여 분석용 정제 데이터 추출 작업을 진행하였습니다.
검색 로그 데이터 중 중복 및 미완성 글자를 제거하는 MapReduce와 다른 성격의 데이터를 mapping 처리 하는 MapReduce를 작성하였습니다.

2016.03~2016.04 L화학 전지 데이터 분석시스템 구축(Phase1)
 RDBMS와 HDD에 저장된 로그파일을 수집 및 저장 후 로그에 대해서 분석 및 조회 업무를 수행하였습니다.
대용량의 로그데이터의 빠른 Read/Write를 처리 할 수 있도록 HBase를 이용하였으며, SQL-Like한 Apache Phoenix를 이용하였습니다.

2016.04~2017.04 L통신사 시스템 운영업무
 무선단말기 물류관리 파트에서 운영업무를 수행하였습니다.
영업점에서 사용되는 프로그램의 기능을 개발 구현하거나 현장에서 이상오류라고 판단되는 건에 대해서 trouble shooting하였습니다.

2017.05~현재 팀내 빅데이터플랫폼 R&D
 고객社에 납품한 빅데이터플랫폼에 대하여 기술지원을 수행합니다.
또한 팀내 플랫폼을 HDP에서  맞춰 플랫폼의 eco system 플랫폼 구축 및 업그레이드 업무를 담당하고 있습니다.
```

#### 가장 기억에 남는 프로젝트/ 업무 경험에 대해 과제,해결방법 등에 대해 상세히 기술해주세요

```
L통신사 프로젝트 목적은 당시 서비스 하고 있던 mobile VOD Service의 추천 시스템 개선 및 빅데이터 시스템 구축이었습니다.
총 3단계로 나뉘어 진행 될 프로젝트의 1단계(phase1)에 투입되었습니다.

L통신사 프로젝트를 진행할 당시 프로젝트 결과물에 대한 정의가 명확히 내려지지 않은 상태로 진행하게 되었습니다.
고객의 니즈를 만족시키기 위해 제공받은 데이터로부터 유의미한 분석결과를 낼 수 있도록 분석팀과 협의 후, HiveQL 작성과 MapReduce 작성을 통하여 데이터 전처리 작업을 진행하였습니다.
미완성 단어 판별에 대한 데이터의 전처리를 HiveQL에서는 'LIKE "%<txt>%"'를 통해 진행하게 되는데 이 경우 모든 row를 두 번 스캔한 뒤 result를 생성하기 때문에 비효율적이라 판단하고 Mapreduce mapper를 통해 처리하는 데이터를 줄이고 처리속도를 상승시켰습니다.

다른 이슈로는 프로젝트 중간 산출물 제출의 due date가 얼마 남지 않았음에도 클러스터 장비가 들어오지 않아 일정에 차질이 있었습니다.
작업을 진행하기 위해 L통신사의 다른 프로젝트의 클러스터에서 임시로 작업을 진행한 뒤 장비가 들어왔을 때 데이터 및 연결설정 정보들을 migration하였습니다.
 oozie workflow를 export하여 데이터 수집 및 전처리용 워크플로우를 옮기기고 새 클러스터에 HDFS데이터를 새 클러스터에 복사하였습니다.
 hive metastore정보가 저장되어 있던 mysql데이터를 dump를 통해 백업하였고 dump file을 새클러스터에 넣은 뒤 새 클러스터에 수집 및 전처리 환경을 migration하였습니다.

마지막으로 데이터 수집에 대한 이슈가 있었습니다.
L통신사에서 분석하길 원하는 데이터는 RDBMS 뿐만 아니라 타 업체에서 로그파일을 별도로 생성하고 타 업체의 클라우드에서 보관이 되고 있었습니다.
만약 지금 처리한다고 했을 때, 클라우드 서비스가 AWS나 Azure라는 가정하에 Apache Nifi를 통해 처리할 수 있겠으나 당시 dataflow를 처리할 수 없어, 별도 FTP 서버를 구축한 뒤 타 업체에서 서버로 파일을 올리면 특정 시간 뒤에 HDFS에 적재할 수 있도록 스케쥴을 등록하여 데이터를 수집하였습니다.

```
